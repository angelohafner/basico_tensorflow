# -*- coding: utf-8 -*-
"""Tutorial_TensorFlow_Funcao_Quadratica.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QzKsDwM4M_FlmL56N1xo34IzHNgKydy-

# Tutorial de Introdução ao TensorFlow com Função Quadrática
Neste tutorial, vamos construir uma rede neural simples usando TensorFlow para prever a função quadrática $y = x^2$.
Isso nos permitirá entender conceitos como:
- Definir um modelo de rede neural
- Camadas intermediárias
- Treinamento do modelo
- Visualização dos resultados
"""

# Importar as bibliotecas necessárias
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import matplotlib.pyplot as plt

"""## 1. Gerar os dados de treino
Vamos criar uma série de números para `x` e calcular `y = x^2`.
"""

# Gerar dados de entrada (x) e suas saídas correspondentes (y = x^2)
x_train = np.linspace(-1, 1, 1000)
# Normalizar os dados de entrada (x)
# x_train_norm = (x_train - np.mean(x_train)) / np.std(x_train)  # Normalização
y_train = x_train**2

"""## 2. Definir o modelo
Agora vamos construir o modelo de rede neural. Ele terá uma camada intermediária com 16 neurônios e uma camada de saída com 1 neurônio.
"""

# Criar o modelo sequencial
model = Sequential()

# Adicionar uma camada densa intermediária com 16 neurônios e função de ativação ReLU
model.add(Dense(64, input_dim=1, activation='tanh'))
model.add(Dense(32, activation='tanh'))
model.add(Dense(32, activation='tanh'))

# Adicionar uma camada de saída com 1 neurônio (prevê y)
model.add(Dense(1))

"""## 3. Compilar o modelo
Agora vamos compilar o modelo usando o otimizador Adam e a função de perda de erro quadrático médio (MSE).
"""

# Compilar o modelo
model.compile(optimizer='adam', loss='mean_absolute_error')

"""## 4. Treinar o modelo
Agora vamos treinar o modelo por 50 épocas.
"""

# Treinar o modelo com os dados gerados
history = model.fit(x_train, y_train, epochs=500, verbose=0)

"""## 5. Visualizar a evolução do treinamento
Vamos agora visualizar o gráfico da perda (erro) ao longo das épocas para ver como o modelo está se ajustando.
"""

# Plotar a evolução da perda durante o treinamento
plt.plot(history.history['loss'])
plt.yscale('log')
plt.title('Evolução da Perda Durante o Treinamento')
plt.ylabel('Perda')
plt.xlabel('Época')
plt.show()

"""## 6. Fazer previsões com o modelo treinado
Agora, vamos usar o modelo treinado para prever os valores de `y` a partir dos valores de `x` e comparar com os dados reais.
"""

# Fazer previsões com o modelo treinado
x_pred = np.linspace(-4, 4, 100)
y_pred = model.predict(x_pred)

# Visualizar os resultados reais e previstos
plt.scatter(x_train, y_train, label='Dados Originais', alpha=0.3)
plt.plot(x_pred, y_pred, label='Previsões', color='red')
plt.legend()
plt.title('Comparação entre Dados Reais e Previstos')
plt.show()

"""Com isso, finalizamos o tutorial de introdução ao TensorFlow! Você aprendeu a criar e treinar uma rede neural simples para prever a função quadrática $y = x^2$."""